# CpHMetaD_Tutorial

## Aim

This tutorial aims to train users to perform CpH-Metadynamics simulations using the stochastic titration constant-pH Molecular Dynamics method and PLUMED. 

## Objectives

Upon completion of this tutorial users will be able to:
- Write and modify both the CpHMD.settings and PLUMED input file to perform CpH-MetaD simulations ;
- Calculate free energy as a function of the chosen collective variables and the pH of the simulation ;
- Unbias conformational and pH-dependent properties ; 
- Estimate the errors in average protonations and pKa estimates ;
- How to combine multiple CpH-MetaD simulations through binless WHAM procedure ;
- Calculate properties using the WHAM pH weights.

## Software Installation

We will need PLUMED 2.9.0, a GROMACS version 2023 patched with PLUMED and the CpHMD v3.0 for this tutorial. The first two softwares can be installed using the instructions found [here](https://github.com/plumed/cecam2023/blob/main/software.md). For the installation of the CpHMD v3.0, we recommend visiting the [GitHub page](https://github.com/NunoFBOliveira/CpHMD_v3/tree/main) of the CpHMD method by the Machuqueiro group and installing the AMBER version. Following that installation, visit the [CpH-Metadynamics page](https://github.com/Tomfersil/CpH-MetaD/tree/main) by Tomás F. D. Silva and follow the instructions on how to patch the CpHMD v3.0 for modified AMBER $\chi$ OL3 RNA parameters and the metadynamics compatibility using PLUMED. Please follow nad cite the relevant papers mentioned in the GitHub pages. 

## Resources

This tutorial contains the following files:
- .occ files: a type of file that contains protonation data;
- .pdb/.xtc: a reference pdb file and the trajectories necessary for the analysis;
- HILLS:  files that contain the accumulated bias for each pH simulation; 
- .dat: PLUMED input and output files required for analyses in the notebook.

Additionally, several scripts are available for preparation of trajectories and protonation files, to generate PLUMED input files and to obtain their respective output data.

## Introduction to CpH-Metadynamics

Constant pH Metadynamics is a methodological approach that integrates two main ideas: the [stochastic titration Constant pH Molecular Dynamics](https://doi.org/10.1063/1.1497164) method and the [metadynamics](https://doi.org/10.1038/s42254-020-0153-0) method. For a more detailed explanation of how both these methods work, we recommend a deeper dive into the provided links. However, here we will tackle the main rationale behind the [CpH-Metadynamics approach](https://arxiv.org/pdf/2410.16064) and to do that we will tackle the st-CpHMD first.

### st-CpHMD:

The [st-CpHMD method](https://doi.org/10.1063/1.1497164) and other CpHMD methods aim to introduce an additional parameter into MD simulations which is the pH. The introduction of the pH relates to the fact that the standard MD protocols assume fixed protonation states in their residues whereas, in biological conditions, residue titration is dependent on the pH and the surrounding environment. While there are many valid ways to integrate the chemical potential within MD, in this work we use a start-stop approach to change the protonation state along the simulation partitioned into three main steps:

- a Poisson-Boltzmann/Monte Carlo (PB/MC) step ;
- a solvent relaxation step ;
- a MD production step ;

in the PB/MC, protonation free energies are calculated in a single conformation to determine the likelihood of the different protonation states of a titrable site, which are then sampled through a MC procedure until it satisfies a criterion. Upon reassigning the protonation state, a short MD is run with restraints on the solute to allow the solvent to readjust to the new charges. Finally, there is the production MD step, typically 20 ps, which samples the conformational space. After this step, we reinitiate the cycle for how many times are necessary until we reach the desired simulation length. A deeper dive on how we can extract energies from protonation-dependent properties will be addressed on the analysis segment.This method effectively couples discrete protonation states and conformational sampling, thus allowing a more rich description of a biological system.

### Metadynamics integration:

In typical metadynamics simulations, specific degree of freedoms are selected as fundamental for a given biological system. Hence, we accelerate the conformational sampling of the system in function of those degree of freedom called collective variables (CV) by periodically building an history-dependent bias potential. This bias potential is generated by summing Gaussians along the simulation in the CV space. For more details, check the theory behind the [PLUMED tutorial](https://www.plumed.org/doc-v2.9/user-doc/html/advanced-methods.html) on metadynamics.

Effectively, certain degrees of freedom are more challenging to sample and can relate to important conformational properties of the system of interest. Furthermore, these degrees of freedom may be regulated by key pH-sensitive residues or certain conformational ensembles require major conformational transitions triggered by changes in the electrostatic environment. These slow degrees of freedom benefit from enhanced sampling techniques such as metadynamics but also from a CpHMD method that easily changes the protonation state of key residues. This is done by allowing the PLUMED module to be ran in the MD production step of the st-CpHMD method following a pre-defined PLUMED input file with chosen CVs. We will explore how to define these settings in the following section. By integrating PLUMED within the st-CpHMD methodology, we effectively improve the accuracy of average protonation and pKa calculations as the tutorial will show in later sections.

## Setting up a CpH-Metadynamics simulation

Setting up a CpH-Metadynamics simulation requires defining parameters for two sections: the CpHMD section and the PLUMED input file. Previous knowledge on [metadynamics](https://www.plumed.org/doc-v2.9/user-doc/html/advanced-methods.html) and/or CpHMD simulations is helpful.
Examine the CpHMD.settings file. For now, let's observe the main defining settings:

```
###  Start of CpHMD settings (pHmdp) ###
#
########################################
export SysName="A5mer" # Name of our protein or system
export Segments=100 # Number of MD/CpHMD Segments
export Seg_size=10 # Size of each Segment in nanoseconds
export ffDIR="/leonardo/home/userexternal/tfernand/Constant_pH/CpHMD_MetaD/top/XOL3pH.ff"
export ffID=XOL3pH #XOL3pH # Force fields: G54a7pH/CHARMM36pH  --> GROMOS 54a7/CHARMM 36m
export plumed=grid # Static - static potential after metaD ; grid - run metaD using grids instead of running Hills; yes - standard metaD using Hills
export water=opc # Water model used
export pH=XX.XX # Solution pH
export sites="9" # list of residues to titrate or "all" to titrate every residue
export temp=300.0 # Temperature (Kelvin)
export ionicstr=0.01 # Ionic Strength (moles/litre)

```

In this section, we need to define the number of segments and the size of each segment in nanoseconds. In the following exercise, we will manage 100 ns trajectories partitioned into 10 segments of 10 ns each. Another important input is the choice of force field. Popular force fields were specifically modified to incorporate multiple protonation tautomers for different biomolecules (see: [CpHMD-v3.0 Github page](https://github.com/NunoFBOliveira/CpHMD_v3/tree/main)). In this tutorial, we will be studying a uridine nucleobase, so we will use the XOL3pH ff (see the [XOL3pH parametrization](https://github.com/Tomfersil/CpH-MetaD/tree/main/CpHMD_metaD/top/XOL3pH.ff)).

Then it is possible to choose either to perform a plain CpHMD simulation or choose different options for a metadynamic simulation:

- plumed=yes: performs a metadynamics simulation reading from the HILLS every cycle;
- plumed=grid: stores both a GRID and HILLS file. Restarting a segment reads from the GRIDS file. Recommended setting due to speed;
- plumed=static: performs a static potential simulation by reading a previous HILLS file. No more gaussians are added and continues to explore the CV space.

The sites entry is needed to define the titrable sites based on the residue numbering in the .pdb file used as input. It accepts either a number or the all flag. Finally, we need to set system parameters such as the simulation temperature, the pH and the ionic strength (in mol/L) for the PB calculations. FOr more details on the CpHMD settings, check the work done by the Machuqueiro Lab in the previously linked GitHub pages.

Concerning the specific parameters for the metadynamics section, either check the end of the file or the template PLUMED_GRID.dat file. We recommend this setting since it provides a greater advantage in I/O speed compared to the HILLS file.


```
# PLUMED
########################################
# Check if the timesteps and temperature values are consistent with previous CpHMD settings
# Activate MOLINFO functionalities by loading the reference system pdb
MOLINFO STRUCTURE=U1mer.pdb
RESTART # Do not remove this line. This is ignored for the first cycle in each block
# Define the chi angle and sugar puckering using the atom numbers found in the reference pdb file.
chi:  TORSION ATOMS=8,9,19,28
puck: PUCKERING ATOMS=6,8,9,13,11
# Activate well-tempered metadynamics in chi and the Zx component of the sugar puckering
# Define the PACE (frequency of steps) at which gaussians are added and their initial HEIGHT in kJ/mol
# Define the SIGMA (width) of the gaussians on the CV space. Check the CV fluctuations of an unbiased run and use 1/2 or 1/3 as a rule of thumb. 
# Define the biasfactor for the well-tempered. This is an important parameter.
# Define the temperature. It should match the chosen temperature in the CpHMD settings.
# Define the minimum and maximum of the GRID range and the stride at which it is written.
# With these settings, we are reading and writting over the same grid file every N steps. This is computationally lighter and faster to use.  
metad: METAD ARG=chi,puck.Zx PACE=500 HEIGHT=2.0 SIGMA=0.35,0.35 BIASFACTOR=4 TEMP=300 FILE=HILLS GRID_MIN=-pi,-pi GRID_MAX=pi,pi GRID_WSTRIDE=500 GRID_WFILE=GRID GRID_RFILE=GRID 
   
# Print both collective variables on COLVAR file every colvar_stride steps (Xps)
PRINT ARG=chi,puck.Zx,metad.bias  STRIDE=1000 FILE=COLVAR 
```
The main argument is the METAD command. Using the ARG keyword we need to specify the variables concerning our CVs upon the metadynamics bias will be added. In the uridine system that we are studying, it will be the $\chi$ angle and ribose puckering. Then we need to define, for both CVs, the HEIGHT of the Gaussians in kJ/mol, the width of the Gaussians defined by keyword SIGMA, and the PACE (frequency in number of time steps) at which Gaussian are added. The biasfactor and the temp are important parameters since they will define the convergence of the initial barrier height scaling. The defined parameters are standard for a nucleoside simulation using these specific CVs.

Concerning the GRIDS, the bias potential is also written to a GRID file (GRID_WFILE keyword) and then read (GRID_RFILE keyword) on the following cycle. The grid boundaries are defined by GRID_MIN and GRID_MAX, while the frequency of update is done every GRID_WSTRIDE time steps (it should match the PACE).

After carefully choosing the PLUMED.dat parameters and the CpHMD settings, a CpH-Metadynamics simulation can be run. To run a CpH-MetaD simulation, there are available scripts and template settings files in the following path of the [CpH-MetaD GitHub page](https://github.com/Tomfersil/CpH-MetaD/blob/main/CpHMD_metaD/scripts/). These simulations will generate several files:

Simulation/Input data: 
- GRID: the GRID file that is necessary to restart each cycle and segment of the CpH-MetaD. Do not erase between segments;
- HILLS: the accumulated bias potential of each segment ;
- .pHmdp: the general settings for each specific segment ;
- .gro: the last frame of each .xtc segment is stored as a reference to start the following segment ;

Output data:
- .occ: these files have the protonation data stored. Later we will examine them; 
- .mocc: average occupancy of each titrable site;
- .xtc: the MD trajectory of each segment is stored as an .xtc file ;

Simulation information data:
- .log.gz: log file of the simulation ;
- .err.gz: other data concerning GROMACS, PB and MC log information; 
- .info: these files store general information of the cycles performed in each segment;



# Analyzing CpH-Metadynamics simulations

In this tutorial, we will briefly look into different analyses that can be performed using CpH-MetaD. These analysis will be comprised of two parts:

- Conformational analysis
- Protonation analysis

In the conformational analysis, we will evaluate the convergence of chosen Collective Variables (CV's), characterize the CV space and estimate errors. In the protonation analysis, we will estimate average protonations of the titrable site at each pH value, estimate pKas using the Henderson-Hasselbalch equation and calculate errors, while using the metadynamics weights. Furthermore, we will compute the same properties using a WHAM procedure to reweight to obtain smoother and more accurate descriptions of several observables.

## Loading Packages

import sys
import numpy as np
import scipy
from scipy.optimize import curve_fit
import plumed
import math
import pandas as pd
import matplotlib.pyplot as plt

# Conformational Analysis

## Extraction of trajectories and protonation state data

All trajectories and protonation states were extracted locally using the scripts in the data folder. Take notice of them and examine how to extract the information.

## Calculating populations and the free energy in function of the CVs 

Here we use the PLUMED tool to obtain reweighted data on the desired observables, i.e. the chosen CV's: 
- the $\chi$ angle of titrable site : this important property of nucleobases characterizes the relative orientation of the base/sugar. It is defined by the O4'-C1'-N1'-C2 (C,U) or O4'-C1'-N9-C4 (A,G). When the angle is between 0 and 2 radians (-90º to 90º) it is in syn and the base is oriented towards the sugar, while from -pi to 0 and 2 to pi the angle is in anti. This base-flipping is a slow internal degree of freedom therefore a good candidate for a CV. It is also useful to validate our force field against experimental data;

- the sugar puckering: another slow yet important property that refers to the conformation of the ribose. It is defined by the C2' and C3' atoms' relative positions to the plane defined by the C1', O4' and C4' atoms. The C2' endo is defined by the C2' atom above the plane and similarly the C3' endo for the C3' atom. The positioning defines the proximity of the 2'-OH group to the base and also the helix type. These calculations were done locally. 

Biased simulations were performed at 3 distinct pH values: 8.0, 9.0 and 10.0. Since the pKa of uridine is 9.22, then each simulation should exhibit differences in their observables if they are protonation-dependent. And that is what we are going to assess. For that purpose, we need to unbias our simulations and obtain either the weights or the unbiased observables. First, we need to extract the reweighted observables using the HILLS file for each simulation of our system. To do that we need to run the PLUMED driver module on the concatenated trajectory using a modified version of our PLUMED.dat input file. Examine the following cell that generates the PLUMED_rew.dat file. 

```
%%bash
    # Define system name
    sys=U1mer
    # Iterate through each simulation pH
    for pH in 09.00 09.25 09.50
    do
    #Generate a new PLUMED file for each pH
    cat > plumed_rew_${pH}.dat << EOF
    
    # Provide molecular information given the system pdb
    MOLINFO STRUCTURE=data/${sys}.pdb
    # Define the atoms for the chi torsion angle CV
    chi:  TORSION ATOMS=8,9,19,28
    # Define the atoms for the sugar puckering CV
    puck: PUCKERING ATOMS=6,8,9,13,11
        
    # Activate well-tempered metadynamics module using the defined CVs. For the sugar puckering, we want specifically the Zx vector.
    # The PACE is defined to a very large number and the Height to 0.0 kJ/mol because we do not want to add new gaussians.
    # The RESTART=YES to restart the metadynamics, hence read the added Gaussians from the provided HILLS file.
    # The bias factor, GRID boundaries are equal to the ones provided in the simulation.
    metad: METAD ARG=chi,puck.Zx PACE=100000000 HEIGHT=0.0 BIASFACTOR=8 SIGMA=0.35,0.35 FILE=data/HILLS_pH${pH} GRID_MIN=-pi,-pi GRID_MAX=pi,pi RESTART=YES # <- this is the new stuff! 
    
    # Using the REWEIGHT_BIAS, we provided the metad.bias as an argument to obtain the weights.
    as: REWEIGHT_BIAS ARG=metad.bias

    # Unbiased histograms for the observables are obtained by providing the logweights previously defined.
    hhchi:  HISTOGRAM ARG=chi STRIDE=1 GRID_MIN=-pi GRID_MAX=pi GRID_BIN=100 BANDWIDTH=0.1 LOGWEIGHTS=as 
    hhpuck: HISTOGRAM ARG=puck.Zx STRIDE=1 GRID_MIN=-pi GRID_MAX=pi GRID_BIN=100 BANDWIDTH=0.1 LOGWEIGHTS=as 
    # Then we can convert the histograms h(s) to free energies F(s) = -kBT * log(h(s))
    # by using the CONVERT_TO_FES module and then dump the free energies.
    ffchi: CONVERT_TO_FES GRID=hhchi 
    ffpuck: CONVERT_TO_FES GRID=hhpuck 
    # Print out the free energies F(s) 
    DUMPGRID GRID=ffchi FILE=ffchi_${pH}.dat 
    DUMPGRID GRID=ffpuck FILE=ffpuck_${pH}.dat 

# Print to a COLVAR file the chi angle, the Zx component of the sugar puckering and the metad.bias
PRINT ARG=chi,puck.Zx,metad.bias FILE=COLVAR_REWEIGHT_${pH} STRIDE=1 
EOF

# Then we run the plumed driver tool using the following command for each pH simulation. We also define the value of KBT in energy units.
plumed driver --mf_xtc data/${sys}_pH${pH}.xtc --plumed plumed_rew_${pH}.dat --kt 2.5
done

```

From the previous cell, we were able to obtain the weighted histograms, the unweighted properties and the bias used along the frames of the simulation. At this moment, we can extract the information from the COLVAR files and compute the weights w of each frame using w = exp(V/kBT) and then applying each w to each value of the observable. As such, we can obtain weighted averages, free-energy differences between the energy minima and plot the free energy along the chosen observable. 

In the following cells, we will examine how the pH impacts the CVs of our system by comparing the populations of the syn/anti and the C2'/C3' endo conformations and their free energy differences. 

### Q1. Does increasing the pH, thus the number of deprotonation events, impact the thermodynamic balance between these distinct conformations? 

```
KbT = 2.5
pH_values = ['08.00','09.00','10.00']
for pH in pH_values:
    
    # Load the FES file and the COLVAR file.
    ffChi   = np.loadtxt("ffchi_"+str(pH)+".dat")
    Chi     = np.loadtxt("COLVAR_REWEIGHT_"+str(pH))
    
    # Extract the information into distinct columns: Time, Chi, Puck, metad.bias
    col = pd.read_csv('COLVAR_REWEIGHT_'+str(pH), sep=" ", header=None, skiprows=range(0,3),usecols=[1,2,3,4],names=["Time", "Chi", "Puck", "metad.bias"])
    # Define the maximum value of the bias. This will provide a better numerical approximation.
    maxim=np.max(col['metad.bias']) 
    # Define the weight for each frame as defined by w=exp(V(s)/kBT).
    weights=np.exp((col['metad.bias']-maxim)/KbT)
    # Then normalize the weights
    weights=weights/np.sum(weights)
    # Add a new columnd with the weights to our dataframe.
    col['weight']=weights

    sweights = []
    aweights = []

    # Split the weight between syn (0<= syn <=2) and anti according to the Chi values.
    for index in range(0,len(col)):
        cval = col['Chi'][index]
        wval = col['weight'][index]
        if 0 <= float(cval) <= 2:            
            sweights.append(wval)
        else:
            aweights.append(wval)
    
    # Then we each population average as the sum the normalized weights
    smean  = np.sum(sweights)
    amean = np.sum(aweights)
    # Through the relation of Fi = - KbT ln(1/N Sum(x)), we know the free energy of a minimum
    # Then the free energy difference can be given by deltaF_{x-y} = - KbT ln(meanX/meanY) 
    # Since the difference of the logs is equal to the log of the quotient, we assume KbT = 1 in this case
    fed = -np.log(smean/amean)*KbT

    # Then we can print the free energy difference between the two populations and their average value for chosen property (Chi angle)
    #### Exercise: Try to print the population values of both states at the different pH values:
    #HIDDEN
    print("The free energy difference, at pH {}, (syn to anti) on the Chi angle CV is {:.3f} KJ/mol and the syn pop is {:.3f}".format(pH,fed,smean))
    #ENDHIDDEN

    #### Exercise: Try to plot the free energy in function of the $\chi$ angle CV  at the different pH values:
    # We can also plot the data as degrees instead of radians by converting rad*180/pi
#SOLUTIONFILE=notebooks/solution.ipynb
#HIDDEN
    plt.plot(ffChi[:,0]*180/np.pi,ffChi[:,1],label="pH"+str(pH),linewidth=2)
    plt.title("Chi Angle")
    plt.xlabel("Chi CV")
    plt.ylabel("free energy [kJ/mol]")
    plt.legend(ncol=1)
plt.show()
#ENDHIDDEN
```

### Q2. Calculate the By observing the plot and examining the populations' values, what can we learn from the pH dependence of this system?

Wt-metadynamics simulations depend on providing enough transitions across the defined range of the CV space to obtain sufficient sampling and a good description of the desired observables. As such, we need to examine if the number of transitions across the full CV range and if there is enough sampling in the transition regions which are typically of high energy. 

```
for pH in pH_values:
    # Load the data from the COLVAR file
    Chi     = np.loadtxt("COLVAR_REWEIGHT_"+str(pH))
    # Plot the time series 
    plt.plot(Chi[:,0]*2/1000,Chi[:,1],label="pH"+str(pH),marker="o",markevery=25,linewidth=0,alpha=0.6)
    plt.xlabel("Time / ns")
    plt.ylabel("$\chi$ Angle")
    plt.legend(ncol=1)
plt.show()

```
### Q3. Are there enough transitions across the full range to state that we are sampling this specific CV space?

Another important property to evaluate is the convergence of the free energy difference. In a simple system such as this, convergence can be assessed by measuring the free energy difference along the simulation time. Then, we will be able to use the converged portion of the trajectory to calculate other observables and estimate standard errors.

To obtain the convergence, we need to compute the free energy along each CV value using the sum_hills module every N steps of the simulation.

```
for pH in ["08.00", "09.00", "10.00"]:
    !plumed sum_hills --hills data/HILLS_pH${pH} --stride 1000 --idw "chi" --kt 2.5 --outfile ff.chi_pH${pH}_

```

The sum_hills module is used to sum the Gaussians stored in the HILLS file by using the --hills keyword. Then it is possible to select one specific CV, using the --idw keyword, to obtain their specific bias.

Then, by iterating through each pH value, we can extract the data of each file and compute the free energy difference of the minima defined by the syn/anti criterion used previously.

```
# Calculate free energy difference between syn and anti minima.

# Since we defined stride=1000 in sum_hills, the tau is equivalent to 10 (1ns).
tau=1 
# Then we cycle through pH and each obtained free energy profile.
for pH in pH_values:    
    DeltaF=[]

    for n in range(0,101):  
        # Load the data for each file. 
        filename="ff.chi_pH"+str(pH)+"_"+str(n)+".dat"
        if os.path.isfile(filename):
            # Import fes file into pandas dataframe
            data=plumed.read_as_pandas(filename)
            # Find minimum value of fes
            minf =np.min(data["projection"])
            F0=0.0; F1=0.0
            
            # Then we convert the free energy at each value of the CV 
            for j in range(0, len(data["chi"])):
                chi = data["chi"][j]
                # Calculate probability
                p = np.exp((-data["projection"][j]+minf)/KbT)
                # And we integrate in one of the two minima
                if(0<=chi<=2.0):   F0 += p
                else: F1 += p
            # Calculate free energy difference and add to list
            DeltaF.append(-KbT*np.log(F0/F1))    
            time = np.arange(0,len(DeltaF)*tau,tau)
    # Then we plot the data
    plt.plot(time,DeltaF,label="F1") 
    plt.legend()
    plt.title("pH"+str(pH))
    plt.xlabel("Simulation time (ns)")
    plt.ylabel("DeltaF [kJ/mol]")
    plt.show()

```

### Q4. Did the free energy difference converge quickly and how much should we discard of our trajectory?

After assessing the convergence of our simulation and defining how much should we discard, we can perform some statistics using block analysis and a bootstrap approach on the converged part of our trajectory. 

First, we are going to reproduce the plot of the free energy as a function of the $\chi$ angle with the standard errors.

```
# First, we define a function to partition the trajectory into blocks
def partition_array(arr, chunk_size):
    return [arr[i:i + chunk_size] for i in range(0, len(arr)-1, chunk_size)]
```

```
# Once again, we iterate through each pH simulation
for pH in pH_values:
    # Load the dataframe
    col = pd.read_csv('COLVAR_REWEIGHT_'+str(pH), sep=" ", header=None, skiprows=range(0,3),usecols=[1,2,3,4],names=["time", "chi", "puck.Zx", "metad.bias"])
    # Discard non-equilibrated segments and define data sets
    chi    = np.array(col['chi'].loc[col['time']>10000])
    bias   = np.array(col['metad.bias'].loc[col['time']>10000])
    maxim  = np.max(bias) #
    weight = np.array(np.exp((bias)/KbT))

    # Define the number of blocks for the converged segment
    bnumber = 5
    # Define the block size
    bsize   = int(len(chi)/bnumber)
    # Use the function to partition each data set.
    bl_chi     = partition_array(chi,bsize)
    bl_weight  = partition_array(weight,bsize)
     
    # Define the parameters for bootstrap
    samples_chi = []
    nsamples    = 1000
    nbins       = 100
    
    # Iterate through the number of samples
    for j in range(nsamples):
        #Generate a list of n blocks to generate subsamples
        n = len(bl_chi)   
        blocks = np.random.choice(n,n,replace=True)
        iter_chi     = []
        iter_weight  = []
        # Generate the nem sub sample with the randomized blocks
        for i in blocks:
            iter_chi.append(bl_chi[i])
            iter_weight.append(bl_weight[i])
        # Generate a reweighted histogram with the new data and weights
        hist_chi, bin_edges   = np.histogram(iter_chi,bins=nbins,weights=iter_weight,density=False)
        # Convert the reweighted histogram to a free energy surface
        fes_chi   = np.array(-KbT*np.log(hist_chi))   
        # Append the output to the list
        samples_chi.append(fes_chi)
    # After obtaining the outputs for all the new samples, estimate the std_deviation
    std_chi    = np.std(samples_chi,axis=0)
    
    # Estimate the mean
    mean_chi   = np.mean(samples_chi,axis=0)
    
    # Then plot the histogram with errors defined as the std_dev
    bin_edges = np.histogram(chi,bins=nbins)[1]
    bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2
    plt.errorbar(bin_centers,mean_chi,yerr=std_chi,label="pH"+str(pH))
    x_tick = np.arange(-1,1.1,0.5)

    x_label = [r"$-\pi$",r"$-\frac{\pi}{2}$", r"$0$", r"$+\frac{\pi}{2}$",r"$\pi$"]
    plt.minorticks_on()
    plt.xticks(x_tick*np.pi,x_label, fontsize=16)
    plt.yticks(np.arange(-100,-40,10),fontsize=16)
    plt.xlim(-np.pi,np.pi)
    plt.ylim(-90,-40)
    plt.ylabel("F($\chi$) / kJ.mol$^{-1}$",fontsize=16)
    plt.xlabel("$\chi$ Angle$ / rad$ ",fontsize=16)
    plt.legend(fontsize=12,loc="upper left")
plt.tight_layout()
plt.show()

```
### Q5. How does the new free energy plot compare to the one obtained through the PLUMED module? How big are the error estimates?

### Q6. Attempt to reproduce the previous analyses for the Zx component of the sugar puckering. How does it compare to the $\chi$ angle? 

So far, we have examined how an individual CV depends on the simulation pH and how the population balance of syn/anti and C2'/C3' endo change across the different simulations. Now, we want to compare the 2D free energy surface along all pH values and observe how the energy minima relate to each other.

## Plotting 2D Free Energy Surface in function of the metadynamics CVs 

First, we need to once again use the sum_hills module to read the HILLS file of each simulation and generate a file with the free energies at each grid point. The grid is defined by both CVs and, at each point, an energy value is assigned after the module sums all the Gaussians deposited during the simulation that are stored in the HILLS file. 

```
%%bash
# For each pH value, we generate a fes.dat file
for pH in 08.00 09.00 10.00
do
    # We define a grid of 100x100 and we read each pH simulation HILLS file
    plumed sum_hills --bin 100,100 --hills data/HILLS_pH${pH}
    mv fes.dat fes_pH${pH}.dat
done

```
After generating each fes_pH.dat file, we can plot the data and it should look like the following plot:

```
for pH in pH_values:
    # Load the data of each fes file.
    X,Y,Z= np.loadtxt('fes_pH'+str(pH)+'.dat',unpack=True)[:][0:3]
    Z-=np.min(Z)
    print(X.shape,Y.shape,Z.shape)
    temp_counter=0
    total_line_counter=0
    block_count_finished=False
    
    with open('fes_pH'+str(pH)+'.dat') as f:
        for count,line in enumerate(f):
            if line != "\n" and '#' not in line:
                temp_counter+=1
            if line == "\n" and block_count_finished==False:
                block_line_counter=temp_counter
                block_count_finished=True
            if line != "\n" and '#' not in line:
                total_line_counter+=1
    print('lines total: ', total_line_counter)
    print('X shape: ',block_line_counter)
    print('Y shape: ', int(total_line_counter/block_line_counter))

    shapeX=block_line_counter
    shapeY=int(total_line_counter/block_line_counter)

    X= np.reshape(X, (shapeY,shapeX))
    Y= np.reshape(Y, (shapeY,shapeX))
    Z= np.reshape(Z, (shapeY,shapeX))


    plt.figure(figsize=(10,8))
    levels=np.arange(0,30,3)
    plt.contourf(X, Y, Z,levels,cmap='jet')
    cbar = plt.colorbar(ticks=levels)
    cbar.set_label(r'$\frac{kJ}{mol}$', rotation=0, labelpad=20,weight='bold',fontsize=20)
    cs=plt.contour(X, Y, Z, levels, colors='black',linewidths=0.5)
    cbar.ax.tick_params(labelsize=15) 
    plt.ylim(-1, 1.0)
    plt.xlim(-np.pi,np.pi)
    plt.title('free energy surface',fontsize=15)


    x_pi   = X*180/np.pi
    x_tick = np.arange(-0.5,0.6,0.5)

    x_label = [r"$-\frac{\pi}{2}$", r"$0$", r"$+\frac{\pi}{2}$"]
    plt.title("pH "+str(pH))
    plt.xticks(x_tick*np.pi,x_label, fontsize=15)
    plt.yticks(fontsize=15)
    plt.xlabel(r'$\chi$',fontsize=15)
    plt.ylabel(r'$puck.Zx$',fontsize=15)
    plt.hlines(0,-np.pi, np.max(X),linewidth=0.5,linestyle='dashed')
    plt.vlines(0,-1, 1,linewidth=0.5,linestyle='dashed')
    plt.tight_layout()
    plt.show() 

```
### Q7. Do we identify differences in the energy minima and barriers across the different pH values? What can we say about the system?

# Protonation Analysis

Conformational analyses are fundamental in identifying energy minima, estimating populations of the chosen CVs and other observables, thus assessing how the system behaves at different pH values. Nevertheless, there is an another dimension to CpH-Metadynamics simulations which concerns the protonation analysis.

When we consider how the system behaves at different pH conditions, we are evaluating how the protonation balance (i.e. the average protonation) of the titrable sites impact the conformational part. Therefore, it is important to consider how the protonation states change throughout the simulation or what is the average protonation of different energy minima. One important and distinctive property is the pKa. 

The pKa is the pH at which 50%  of the population of a titrable site is protonated and the other 50% is deprotonated. Hence the pKa measures the proton binding affinity of a titrable site at a given pH value. Typically, if the solution pH < pKa, then the population of protonated states is more likely to be larger than the population of deprotonated states. If the pH > pKa, then the population of deprotonated states is likely to be larger than the population of protonated states. At pH=pKa, the protonation and deprotonation probability is equal, thus there is a thermodynamic equilibrium. 

The pKa is typically associated with the Henderson-Hasselbalch equation, which describes the relationship between the pKa, pH and the balance between the protonated and deprotonated populations:

$$ pH = pKa + log(\frac{[A-]}{[AH]}) $$

Usually, changes in pKa are measured as pH units, however, they can be translated into kJ/mol. pH variations can be measured as a $\Delta\Delta$ G of the protonation-free energies at two distinct pH values. Since the protonation-free energy can be described as:

$$ \Delta\text{G} = -ln10*RT*(pKa - pH) $$ 

where R is the gas constant, T is the temperature in Kelvin. Then the energy associated with a pH unit change is:

$$ \Delta\Delta\text{G} = -ln10*RT*(pH_f - pH_i) $$

which for a $ \Delta pH=1$ is roughly:

$$ \Delta\Delta\text{G} \approx -5.7 \text{kJ/mol at 298K} $$

These energetic contributions can impact significantly thermodynamic equilibria, change conformational probabilities and balance between populations. Therefore, using these relationships, we will see how we are able to plot titration curves, estimate pKa values and measure energy differences using CpH-metaD simulations. 

In the uridine system, the nucleobase has a pKa of 9.22 at the N3 atom. This means that at pH < pKa, most of the population should be protonated, hence in a neutral state. While for  pH >  pKa, most of the population should be deprotonated, hence in a negatively charged state. How do these charge variations impact our system? Can we measure changes in protonation at different pH values and along the simulation time? Is each energy minima distinguishable by their average protonation? If so, then why and how does electrostatics play a role?

These are all questions to be addressed in the following section.

## Extracting the protonation data

We need to extract the protonation data stored in the .occ files. These files contain information of the proton occupation state of each titrable site along segments of the simulation. These files are generated after each cycle of CpHMD and the total number of lines matches the $ Time_{seg}/\tau_{p} $, which is the time of segment (1000 ps) over the frequency of protonation (20 ps). 

Each column corresponds to a distinct titrable site and each row to different timestamps (typically every 20 ps). Then the occupation state is defined by the parametrized states found in the St-XOL3_DelPHi folder. For example, the uridine has two states: URN0 and URN1. URN0 refers to the neutral (0) state, hence the protonated state, while URN1 refers to the charged (-1) state, hence the deprotonated state. In the .occ file, if the occupation state is 0, then it means it is protonated. However, for the adenine, the AR0 also refers to the neutral state, however in this case it is the deprotonated state, and AR1 is the protonated (+1) state. Hence in this specific case, the protonation and occupation states match and we don't need to correct.
Typically, binary protonable sites  do not need to be corrected, as for the adenine and cytidine, while deprotonable sites (uridine and guanine) require this conversion to obtain the protonation states. Sites with multiple tautomers always need a correction since in those cases, each occupation state refers to a different position of the proton.

First, we are going to generate a data frame to store all the data found in the .occ files for the different pH values.

```
# First we create a pandas dataframe for time and protonation states
protdf    = pd.DataFrame(columns=['Time','Protonation'])
# We define the number of segments of our simulation
segs      = range(0,11)
prots     = {}
pH_values = ['08.00','09.00','10.00']
# We define the frequency of protonation as in the CpHMD settings (20ps)
taup      = 20

# Create a dictionary for the data
prots = {"pH":[],"Time":[],"Protonation":[]}

# We iterate through each pH
for pH in pH_values:
    # Then for each segment
    for seg in segs:
        # We obtain the time range of each segment
        time = seg*10000-10000
        # Get the occ files from the data folder
        path = "data/occ_pH"+str(pH)+str("/")
        itemList =  os.listdir(path)
        # Iterate through each .occ file to obtain the protonation states
        for file in itemList:
            if ".occ" in file and seg == float(file[-7:-4]):
                with open(path+file) as f:
                    for line in f:
                        # Save the time, pH and protonation state
                        prots["Time"].append(int(time))
                        prots["pH"].append(pH)
                        prots["Protonation"].append(float(line.strip()))
                        time += taup
    
protdf = pd.DataFrame.from_dict(prots,orient='columns')
protdf.reset_index(inplace=True)
print(protdf)

```

After extracting all the data and assigning the proper timestamps, we can define the frequency of protonation. While we only calculate the protonation information every 20~ps, in reality, we can propagate the stored protonation states to the intermediate frames within each protonation calculation. If the simulation timestep is 2 ps and the $\tau_{p}$ is 20 ps, then the protonation states of these intermediate frames correspond to the state assigned in the previous cycle. 

```
dfs  = []
# Define the frequency of protonation
taup = 20
# Define the timestep of the simulation
taus = 2

for pH in pH_values:
    # Get last time for each pH series based on occ
    pH_time = protdf['Time'].loc[protdf["pH"]==pH].max()
    # Expand the fixed protonation to frames every 2 ps (simulation)
    tmp = pd.DataFrame(protdf.loc[protdf["pH"]==pH])
    new_pH_time = pd.Series(range(0, pH_time + taup, taus), name='Time').to_frame()
    # Merge and propagate the protonation based on both dataframes
    final_protdf = pd.merge_asof(new_pH_time, tmp, on=["Time"])#,direction='forward')
    dfs.append(final_protdf)

# Concatenated dataframe of all pH data   
final_protdf = pd.concat(dfs)
# Examine the dataframe
print(final_protdf)

```

Since we are performing CpH-Metadynamics simulations, we require the weight data from the accumulated bias in the simulation. Protonation and conformation are intrinsically coupled, then biased conformations dictate that their protonation states should also be unbiased. To do that we need to obtain the weights and correctly assign them to the corresponding frames. 

```
# Define a list for the weighted dataframes
wprot = []

# Iterate through each pH value
for pH in pH_values:
    # Load the data of COLVAR
    col = pd.read_csv('COLVAR_REWEIGHT_'+str(pH), sep=" ", header=None, skiprows=range(0,3),usecols=[1,2,3,4],names=["Time",'chi','puck.Zx', "metad.bias"])
    # Define the maximum bias for a better numerical approximation
    maxim=np.max(col['metad.bias']) 
    # Calculate the weights
    weights=np.exp((col['metad.bias']-maxim)/KbT)
    # Normalize the weights
    weights=weights/np.sum(weights)
    # Define a new column in the dataframe
    col['Weight']=weights
    # Correct the time column
    time = np.array(col['Time']*2)
    col['Time'] = time
    # Merge the two dataframes (protonation and COLVAR)
    pdf1 = pd.merge(final_protdf.loc[final_protdf['pH']==pH], col[['Time','chi','puck.Zx','Weight']],left_on="Time",right_on="Time",how="left")
    # Append each pH dataframe to the list    
    wprot.append(pdf1)

# Create dataframe with Weights
rewprot = pd.DataFrame(columns=['pH','Time','Protonation', 'Weight'])
# Concatenate all pH dataframes into a single on
rewprot = pd.concat(wprot)
rewprot.drop('index',axis=1)
# If there are any rows with nan values due to mismatch when sims are not complete. This should be commented if the simulation ended
# To check for possible mismatch errors
rewprot=rewprot.dropna()

```

### Q8. Examine the final dataframe. Do the timestamps of the protonation states match the conformational data? Are all the pH values present?

After obtaining the final dataframe with all the pH values, protonation and conformation data and the weights, we can calculate average protonations, derive a titration curve and estimate the pKa. To plot a titration curve, we need to redefine the Henderson-Hasselbalch (HH) relationship between pH, pKa and protonation. We can rewrite the HH function as follows:

$$ <P> = \frac{1}{1+10^{pH-pKa}} $$

where <P> is the average protonation at a certain pH value, pH is the assigned value of the simulation and the pKa is the fitted parameter. However, we are dealing with biased simulations, then we need to calculate the weighted average protonations:

$$ <P^*> = \frac{\sum_i P_i \times e^{\frac{B_i}{kBT}}}{\sum_i e^{\frac{B_i}{kBT}}} $$

where <P*> is the weighted average protonation, B_i is the accumulated bias accumulated at the end of the metadynamics simulations calculated on the coordinates corresponding to the i-th frame. Knowing this relationship and how to get the weighted protonation averages, we can fit the simulation data to the HH function and obtain a pKa estimate.

```
## Calculate average protonation for each pH value
data = []
x = []
y = []
w = []

for pH in pH_values:
    # We discard the equilibration time obtained previously
    equil  = 00000
    tlimit = 100000
    # Load the dataframe with all the data
    vals   = pd.DataFrame(rewprot[['pH','Protonation','Weight']].loc[(rewprot["pH"]==pH) & (rewprot["Time"] >= equil)& (rewprot["Time"] < tlimit)])
    weights = vals["Weight"]
    weights = weights/np.sum(weights)
    # Convert the occs into prot states
    occs   = vals["Protonation"] 
    # Remember that for uridine and guanine, the 0 state is the neutral/protonated state.
    prots  = 1-np.array(occs)
    
    # Obtain the weighted average using the normalized weights
    avx = np.sum(prots*weights)
    data.append((pH,avx))
    print(pH,avx,np.sum(prots)/len(prots))

```

### Q9. What can we determine from the average protonations? Do they follow an expected trend?

After obtaining the reweighted data, now we can use the HH relationship to plot a titration curve and determine the uridine pKa. 

```
# Define a tolerance for the upper and lower limtis of average protonation
# Average protonations too close to the upper (1) and lower (0) bounds should not be used
tol = 0.01  
for val in data:
    if val[1] > tol and val[1] < 1-tol:
        x.append(float(val[0]))
        y.append(val[1])

# Define arrays for the pH, protonation and weight data               
x = np.array(x)
y = np.array(y)

# Obtain an initial guess of the pH closer to the pKa     
minndx = 0
for i in range(len(y)):
    if abs(0.5-y[1]) < abs(0.5-y[minndx]):
        minndx = i
# This guess will be used as a reference for the HH function            
pKainit = x[minndx]
    
def Hill(x, pKa, n):
    return 1.0 / (1.0 + 10.0**(n*(x - pKa)))
def HH(x, pKa):
    return 1.0 / (1.0 + 10.0**(x - pKa))
    
params = curve_fit(HH,x,y,p0=[pKainit])
    
x_new = np.linspace(-5,14,1000)
y_new = HH(x_new,params[0][0])
print('## {:5.2f}'.format(params[0][0]))
pKa_fit = '{:5.2f}'.format(params[0][0])


plt.tight_layout()
plt.xlabel("pH")
plt.ylabel("Protonation")
plt.xlim(6.0,11.2)
plt.plot(float(pKa_fit),0.5,"ro")
plt.plot(x,y,"ko")
plt.annotate(pKa_fit,(float(pKa_fit),0.5))
plt.plot(x_new,y_new)

```

Although the final pKa result is slightly underestimated by our simulations, as the experimental pKa is 9.22, the simulations were done on our approach that aims to reflect pKas in an RNA construct and not the single nucleoside. As such, this result is expected. However, one should take notice of the analysis steps required to achieve the result.

Additionally, using the previous rationale, we can apply a bootstrap approach to determine some statistics on the protonation data. For instance, we evaluate the confidence in our estimates by estimating the standard error and plotting histograms of the subsamples. First, we run the function that partitions the data into blocks and generates the new samples.

```
def bt_avgprots(data,weights,nblocks,nsamples):
    data_blocks    = np.split(data,nblocks)
    weights_blocks = np.split(weights,nblocks)
    bt_samples     = []
    #
    for i in range(nsamples):
        new_data   = []
        new_weight = []
        blocks = np.random.choice(nblocks, nblocks, replace=True)
        for j in blocks:
            new_data.append(data_blocks[j])
            new_weight.append(weights_blocks[j])
        prot_tmp = np.average(np.array(new_data),weights=np.array(new_weight))
        bt_samples.append(prot_tmp)
    
    return bt_samples

```

